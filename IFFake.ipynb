{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1A5uGnhkS6d0nOjzRxs28x3APeDopF-5k",
      "authorship_tag": "ABX9TyPQ2ClTf7mJKMzGHvHJQmF1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marizzxxxx/PDI-IFFAKE/blob/main/IFFake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7ZSoXSLJtmk"
      },
      "outputs": [],
      "source": [
        "!pip install gradio Pillow facenet-pytorch==2.5.2 torch==2.1.0 opencv-python grad-cam pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import zipfile\n",
        "import cv2\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image"
      ],
      "metadata": {
        "id": "JUKSD5kaJwDH"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(\"//content/drive/MyDrive/PDI/PDI1/examples.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "mtcnn = MTCNN(\n",
        "    select_largest=False,\n",
        "    post_process=False,\n",
        "    device=DEVICE\n",
        ").to(DEVICE).eval()\n",
        "\n",
        "model = InceptionResnetV1(\n",
        "    pretrained=\"vggface2\",\n",
        "    classify=True,\n",
        "    num_classes=1,\n",
        "    device=DEVICE\n",
        ")\n",
        "\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/PDI/PDI2/resnetinceptionv1_epoch_32.pth\", map_location=torch.device('cpu'))\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(DEVICE)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "PfhfJ4iJJxvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input_image:Image.Image, true_label:str):\n",
        "    \"\"\"Predict the label of the input_image\"\"\"\n",
        "    face = mtcnn(input_image)\n",
        "    if face is None:\n",
        "        raise Exception('No face detected')\n",
        "    face = face.unsqueeze(0) # add the batch dimension\n",
        "    face = F.interpolate(face, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "\n",
        "    # convert the face into a numpy array to be able to plot it\n",
        "    prev_face = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
        "    prev_face = prev_face.astype('uint8')\n",
        "\n",
        "    face = face.to(DEVICE)\n",
        "    face = face.to(torch.float32)\n",
        "    face = face / 255.0\n",
        "    face_image_to_plot = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
        "\n",
        "    target_layers=[model.block8.branch1[-1]]\n",
        "    cam = GradCAM(model=model, target_layers=target_layers)\n",
        "    targets = [ClassifierOutputTarget(0)]\n",
        "\n",
        "    grayscale_cam = cam(input_tensor=face, targets=targets, eigen_smooth=True)\n",
        "    grayscale_cam = grayscale_cam[0, :]\n",
        "    visualization = show_cam_on_image(face_image_to_plot, grayscale_cam, use_rgb=True)\n",
        "    face_with_mask = cv2.addWeighted(prev_face, 1, visualization, 0.5, 0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = torch.sigmoid(model(face).squeeze(0))\n",
        "        prediction = \"real\" if output.item() < 0.5 else \"fake\"\n",
        "\n",
        "        real_prediction = 1 - output.item()\n",
        "        fake_prediction = output.item()\n",
        "\n",
        "        confidences = {\n",
        "            'real': real_prediction,\n",
        "            'fake': fake_prediction\n",
        "        }\n",
        "\n",
        "    return confidences, true_label, face_with_mask"
      ],
      "metadata": {
        "id": "5koIXlM8KvBY"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_examples = [\n",
        "    ['/content/drive/MyDrive/PDI/banco de imagens/fake/em-deepfake-no-instagram-mark-zuckerberg-cita-bilhoes-de-dados-roubados-1560354962424_v2_1x1.jpg', 'fake'],\n",
        "    ['/content/drive/MyDrive/PDI/banco de imagens/real/mark.jpg', 'real'],\n",
        "    ['/content/drive/MyDrive/PDI/banco de imagens/fake/papaa.png', 'fake'],\n",
        "    ['/content/drive/MyDrive/PDI/banco de imagens/real/papaaa.png', 'real'],\n",
        "    # Adicione mais exemplos conforme necessário\n",
        "]\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=[\n",
        "        gr.components.Image(label=\"Coloque sua imagem aqui\", type=\"pil\"),  # Updated component import and type\n",
        "        gr.components.Text(label=\"Digite: Real ou fake?\")  # Updated component import\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.components.Label(label=\"Detector:\"),  # Updated component import\n",
        "        gr.components.Text(label=\"Você disse que era:\"),  # Updated component import\n",
        "        gr.components.Image(label=\"Eplicação\", type=\"numpy\")  # Updated component import and type\n",
        "    ],\n",
        "    examples=custom_examples,  # Substitua pela lista personalizada\n",
        "    cache_examples=True\n",
        ").launch()"
      ],
      "metadata": {
        "id": "zMeQwYUsKxw1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "outputId": "16d505da-ec9a-4087-a075-eaaccb800f9c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching examples at: '/content/gradio_cached_examples/419'\n",
            "Caching example 1/4\n",
            "Caching example 2/4\n",
            "Caching example 3/4\n",
            "Caching example 4/4\n",
            "\n",
            "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://108095443b995a5500.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://108095443b995a5500.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}